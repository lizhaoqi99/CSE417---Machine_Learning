{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isUVtIh32QpY"
   },
   "source": [
    "# Homework 5 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVUYkUOixhB9"
   },
   "outputs": [],
   "source": [
    "# Add import statements here\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import mode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FidREiWX2eOL"
   },
   "outputs": [],
   "source": [
    "# To access files in your Google Drive, run this block and follow the instructions\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41rnGJpR2ggr"
   },
   "outputs": [],
   "source": [
    "# To test if the above block worked, run this block\n",
    "#!ls '/content/gdrive/My Drive/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uUO2zD1ep2ag"
   },
   "source": [
    "## Neural Network\n",
    "\n",
    "The `neural_network` function creates a model that learns to classify handwritten digits.\n",
    "\n",
    "Inputs:\n",
    "* `X_train` is the training data\n",
    "* `y_train` are the training labels\n",
    "* `X_test` is the testing data\n",
    "* `y_test` are the testing labels\n",
    "\n",
    "Outputs: \n",
    "* `test_loss` is the loss after evaluating the testing dataset\n",
    "* `test_acc` is the accuracy after evaluating the testing dataset\n",
    "* `predictions` are the models predictions of the testing dataset\n",
    "\n",
    "Note: Have fun and be creative with this assignment!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "80zLYXHwp5ms"
   },
   "outputs": [],
   "source": [
    "def neural_network(x_train, y_train, x_test, y_test):\n",
    "    # Implement model\n",
    "    \n",
    "    # Feel free to change this up, but leave it at first\n",
    "    model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "    # Fit and evaluate\n",
    "\n",
    "    # Calculate predictions\n",
    "\n",
    "    return test_loss, test_acc, predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVvP0vCKqYsx"
   },
   "source": [
    "## Run and Plot\n",
    "\n",
    "Run your neural network code and plot figures below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LEfN9w__p5c1"
   },
   "outputs": [],
   "source": [
    "# Other neural network code here:\n",
    "\n",
    "# Load data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CvotGgJ_2mup"
   },
   "source": [
    "## Random Forest\n",
    "\n",
    "The `random_forest` function learns an ensemble of numBags CART decision trees using a random subset of the features at each split on the input dataset and also plots the  out-of-bag error as a function of the number of bags\n",
    "\n",
    "Inputs:\n",
    "* `X_train` is the training data\n",
    "* `y_train` are the training labels\n",
    "* `X_test` is the testing data\n",
    "* `y_test` are the testing labels\n",
    "* `num_bags` is the number of trees to learn in the ensemble\n",
    "* `m` is the number of randomly selected features to consider at each split\n",
    "\n",
    "Outputs: \n",
    "* `out_of_bag_error` is the out-of-bag classification error of the final learned ensemble\n",
    "* `test_error` is the classification error of the final learned ensemble on test data\n",
    "\n",
    "Note: You may use sklearns 'DecisonTreeClassifier' but **not** 'RandomForestClassifier' or any other bagging function\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7Cuyd_N9rH_"
   },
   "source": [
    "## Run and Plot\n",
    "\n",
    "Run your random forest code and plot figures below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlZ-XeLN2iTv"
   },
   "outputs": [],
   "source": [
    "def random_forest(X_train, y_train, X_test, y_test, num_bags, m):\n",
    "\n",
    "    # Your code here, assign the proper values to out_of_bag_error and test_error:\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.utils import resample\n",
    "    clf_set = []\n",
    "    oob_set = []\n",
    "    for i in range(num_bags):\n",
    "        # obtain bootstrapped datasets\n",
    "        X = resample(X_train, replace=True, n_samples=int(len(X_train)[0]*0.8), random_state=0)\n",
    "        # obtain out-of-bag data points\n",
    "        oob = [xi for xi in X_train if xi not in X]\n",
    "        oob_set.append(oob)\n",
    "        # learn hypotheses\n",
    "        clf = DecisionTreeClassifier(random_state=i, max_features=m).fit(X) \n",
    "        clf_set.append(clf)\n",
    "    \n",
    "    # compute out-of-bag error\n",
    "    error_set = []\n",
    "    index = 0\n",
    "    for xi in X_train:\n",
    "        pred_set = []\n",
    "        for i in range(len(oob_set)):\n",
    "            if xi in oob_set[i]:\n",
    "                clf = clf_set[i]\n",
    "                pred = clf.predict(xi)\n",
    "                pred_set.append(pred)\n",
    "        # obtain the aggregate of all models not trained with (xi,yi)\n",
    "        aggregate_cls = sign(sum(pred_set))\n",
    "        # compute the error\n",
    "        error = 1 if aggregate_cls != y_train[index] else 0\n",
    "        error_set.append(error)\n",
    "        index += 1\n",
    "    out_of_bag_error = sum(error_set)/len(error_set)\n",
    "    \n",
    "    # compute test error\n",
    "    \n",
    "\n",
    "    return out_of_bag_error, test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 3\n",
    "a = 3 if b==3 else 0\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7seATRA9rge"
   },
   "outputs": [],
   "source": [
    "# Other random forest code here:\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw5_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
